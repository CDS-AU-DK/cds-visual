{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More image processing with ```OpenCV```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to include the home directory in our path, so we can read in our own module.\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "import cv2\n",
    "import numpy as np\n",
    "from utils.imutils import jimshow\n",
    "from utils.imutils import jimshow_channel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by seeing more ways that we can manipulate images using ```OpenCV```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dino pal\n",
    "image = cv2.imread(os.path.join(\"..\", \"data\", \"img\", \"trex.png\"))\n",
    "width = image.shape[1]\n",
    "height = image.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rotation__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rotate about a point, we first need to define that point and then use the function ```cv2.getRotationMatrix2D```.\n",
    "\n",
    "This function takes the following arguments:\n",
    "\n",
    "```cv2.getRotationMatrix2D((x_point, y_point), degrees, scale)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getRotationMatrix2D((width/2, height/2), 0, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = cv2.warpAffine(image, M, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow(rotated, \"Shifted down and right\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Translation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dino pal\n",
    "image = cv2.imread(os.path.join(\"..\", \"data\", \"img\", \"trex.png\"))\n",
    "width = image.shape[1]\n",
    "height = image.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To *translate* an image, there is no specific built-in function with ```OpenCV``` to define a translation matrix. \n",
    "\n",
    "Instead, we need to define then translation matrix we want to use.\n",
    "\n",
    "We can do that using ```numpy```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.float64([[1, 0, 0],\n",
    "                [0, 1, 0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the ```cv2.warpAffine()``` function to translate our image.\n",
    "\n",
    "There's some tricky maths involved here - for the mathematically inclined, you can read more [here](https://people.computing.clemson.edu/~dhouse/courses/401/notes/affines-matrices.pdf)\n",
    "\n",
    "But the crucial point is that we're essentially multiplying together the original image by the translation matrix ```M``` that we've just defined, which results in a modified image being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted = cv2.warpAffine(image, M, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow(shifted, \"Shifted down and right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.rectangle(image, start_point, end_point, thickness)\n",
    "cv2.rectangle(image, (50, 200), (200, 225), (0,255,0), 1)\n",
    "jimshow(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Draw circle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(centerX, centerY) = (image.shape[1] // 2, image.shape[0] // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.circl(image, cent_coords, radio, colour, thickness)\n",
    "cv2.circle(image, (centerX, centerY), 50, (255,0,0), 1)\n",
    "jimshow(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Drawing on images is *destructive*! It modifies the image in place and can't easily be removed. \n",
    "\n",
    "If you draw on an image and then decide you want the original image without the drawings on it, you'll need to load the image again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dino pal\n",
    "image = cv2.imread(os.path.join(\"..\", \"data\", \"img\", \"trex.png\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using masks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how bitwise operations work by just starting out with a simple rectangle and circle of white pixels on black backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 300x300 array of zeros\n",
    "zeros = np.zeros((300, 300), dtype = \"uint8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What does the following cell do? Can you explain it natural language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = cv2.rectangle(zeros, (25, 25), (275, 275), 255, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow_channel(rect)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Circle__\n",
    "\n",
    "We can get a circular mask in much the same way, this time using ```cv2.circle()```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circle\n",
    "zeros = np.zeros((300, 300), dtype = \"uint8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Again, can you explain what this is doing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ = cv2.circle(zeros, (150, 150), 150, 255, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow_channel(circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rectangle mask__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask should be same shape as image\n",
    "mask = np.zeros(image.shape[:2], dtype=\"uint8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is this cell doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.rectangle(mask, (100,100), (200, 200), 255, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you expect to see here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow_channel(mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** And what do you expect to see here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow(cv2.bitwise_and(image, image, mask=mask))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Circular mask__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you think this does and what do you expect to see after running the next two cells?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask 'image'\n",
    "mask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "(centre_x, centre_y) = (image.shape[1]//2, image.shape[0]//2)\n",
    "jimshow_channel(cv2.circle(mask, (centre_x, centre_y), 50, 255, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow(cv2.bitwise_and(image, image, mask=mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.join(\"..\", \"data\", \"img\", \"trex.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow(image, \"Original image\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "We've now seen how to load images and split them into their separate colour channels. We've also seen how we can use this to extract colour histograms showing distributions of pixel intensities across each channel. Lastly we've seen how we can use this to plot colour histograms for any given image.\n",
    "\n",
    "- In your groups, rework the code in the cell above into a function which can create a colour histogram for any given image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing histograms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also saw briefly last week in class that we are able to compare images based on their colour histograms. This is something that can be done mathematically in ```OpenCV```. \n",
    "\n",
    "Let's load a different image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.imread(os.path.join(\"..\", \"data\", \"img\", \"t-rex2.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow(image2, \"Image 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extract histograms__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we saw how to extract histograms from images using ```cv2.calcHist()```, specifically for single channels.\n",
    "\n",
    "In the lines below, we're ```cv2.calcHist()``` to extract histograms across all three channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = cv2.calcHist([image], [0,1,2], None, [256,256,256], [0,256, 0,256, 0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = cv2.calcHist([image2], [0,1,2], None, [256,256,256], [0,256, 0,256, 0,256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MinMax normalization__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before comparing histograms, we first have to *normalise* them to occur within a narrower ranger of values. \n",
    "\n",
    "**Question:** Why do think we need to do this?\n",
    "\n",
    "We're doing to use MinMax normalisation, which we calculate in the following way for each value:\n",
    "\n",
    "```norm_pixel = (value-min) / (max-min)```\n",
    "\n",
    "That is to say for every pixel ```value``` we subtract the ```min``` pixel value in the image, then divide that by the ```max``` minus the ```min```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = cv2.normalize(hist1, hist1, 0, 1.0, cv2.NORM_MINMAX)\n",
    "hist2 = cv2.normalize(hist2, hist2, 0, 1.0, cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comparing the first two histograms__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to compare images computing the *Chi-Squared distance*, but there are a range of options available via OpenCV. \n",
    "\n",
    "You can read more [here](https://pyimagesearch.com/2014/07/14/3-ways-compare-histograms-using-opencv-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cv2.compareHist(hist1, hist2, cv2.HISTCMP_CHISQR), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load a new image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = cv2.imread(os.path.join(\"..\", \"data\", \"img\", \"wave.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow(image3, \"Image 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare with image 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3 = cv2.calcHist([image3], [0,1,2], None, [256,256,256], [0,256, 0,256, 0,256])\n",
    "hist3 = cv2.normalize(hist3, hist3, 0, 1.0, cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then show calculate the scores between image and the other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cv2.compareHist(hist1, hist1, cv2.HISTCMP_CHISQR), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cv2.compareHist(hist1, hist2, cv2.HISTCMP_CHISQR), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cv2.compareHist(hist1, hist3, cv2.HISTCMP_CHISQR), 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "In the shared drive ```cds-vis-data```, you'll find a directory comprising 1360 different images of flowers. Many of these are different images of the same flower.\n",
    "\n",
    "In groups, do the following activity:\n",
    "\n",
    "- Pick a random flower from the dataset, load it, and normalize it\n",
    "- Compare that image's colour histogram to every *other* flower in the dataset\n",
    "- Print save the filename of the 5 closest images, along with the distance score you calculated\n",
    "  - **Hint:** use ```pandas```\n",
    "- Qualitatively inspect the images - how does your algorithm perform?\n",
    "- Rewrite your code as a function which takes any input filename from a user and produces the new results showing top 5 closest images for the chosen image\n",
    "\n",
    "This in-class exercise is going to be *Assignment 1* for Visual Analytics, designing a simple *image search* algorithm. The Github classroom repo for this Assignment will go online later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
