{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional kernels - blurring, thresholds, edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to include the home directory in our path, so we can read in our own module.\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "import cv2\n",
    "import numpy as np\n",
    "from utils.imutils import jimshow\n",
    "from utils.imutils import jimshow_channel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image\n",
    "\n",
    "Let's start by loading our dino buddy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(\"..\", \"data\", \"img\", \"trex.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow(image, \"Dino\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring and convolutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```OpenCV``` has built in functions for performing blurring.\n",
    "\n",
    "All we need to do is choose which blurring method we want, and some parameters which define the blur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Averaging__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = np.hstack([\n",
    "    cv2.blur(image, (3, 3)),\n",
    "    cv2.blur(image, (5, 5)),\n",
    "    cv2.blur(image, (7, 7))]\n",
    "    )\n",
    "jimshow(blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gaussian__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third parameter relates to variance around the mean for a Gaussian distribution. For our purposes, we can just set that to ```0```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian blur\n",
    "blurred = np.hstack([\n",
    "    cv2.GaussianBlur(image, (3, 3), 0),\n",
    "    cv2.GaussianBlur(image, (5, 5), 0),\n",
    "    cv2.GaussianBlur(image, (7, 7), 0)]\n",
    "    )\n",
    "jimshow(blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Median__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does not \"invent\" pixel values, kernel removes details and noise\n",
    "blurred = np.hstack([\n",
    "    cv2.medianBlur(image, 3),\n",
    "    cv2.medianBlur(image, 5),\n",
    "    cv2.medianBlur(image, 7)]\n",
    "    )\n",
    "jimshow(blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with blurring, ```OpenCV``` has built in functions for allowing us to perform thresholding. However, we need to perform another couple of steps before we get there."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Simple thresholding__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by reloading the image and converting to greyscale with ```cv2.cvtColor()``` like we saw a couple of weeks back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to greyscale\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using simple thresholding, we want to set a single specific value above which everything is set to white and below which everything is set to black.\n",
    "\n",
    "How do we determine the value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "plt.hist(image.flatten(),256,[0,256])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Blur the image__\n",
    "\n",
    "To get the best results for our edge detection, we first need to blur our image to smooth out the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove high frequency edges with a blur kernel\n",
    "blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "jimshow_channel(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've blurred the image, we then use the ```cv2.threshold()``` function to perform simple thresholding using our predetermined binary threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold \n",
    "(T, thres) = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
    "jimshow_channel(thres)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a black sillhouette on a white background. However, when working with a mask, we want the opposite because we're using ```bitwise_AND```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T, thresInv) = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "jimshow_channel(thresInv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then display the image using the mask generated by our simple threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow_channel(cv2.bitwise_and(image, image, mask = thresInv))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adaptive__\n",
    "\n",
    "The exact same steps are required when performing adaptive thresholding. We load the image, make it greyscale, and use blurring. \n",
    "\n",
    "The only difference is that, this time, we use the ```cv2.adaptiveThreshold()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(image_grey, (5,5), 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adaptive mean threshold__\n",
    "\n",
    "The ```cv2.adaptiveTreshold()``` function requires slightly different combinations of arguments, outlined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_thresh = cv2.adaptiveThreshold(blurred, \n",
    "    255,                            # set values above threshold to white\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C,     # method for computing threshold (mean of neighborhood) \n",
    "    cv2.THRESH_BINARY_INV,          # method for thresholding \n",
    "    5,                              # neighborhood pixel size\n",
    "    10                              # parameter C subtracted from the mean to fine-tune thresholding\n",
    "    )\n",
    "jimshow_channel(am_thresh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've found the edges, we can then use it as a mask, just as with simple thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow_channel(cv2.bitwise_and(image_grey, image_grey, mask = am_thresh))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection follows a similar set of steps again. We always begin by loading the image and making it greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile = os.path.join(\"..\", \"data\", \"img\", \"coins.png\")\n",
    "image = cv2.imread(newfile)\n",
    "grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ```cv2.Sobel()``` function to define horiztonal and vertical sobel kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel operatator\n",
    "sobelX = cv2.Sobel(grey, cv2.CV_64F, 1, 0)  # horizontal kernel\n",
    "sobelY = cv2.Sobel(grey, cv2.CV_64F, 0, 1)  # vertical kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that here we're using 64-bit floating point numbers, while all of our pixel values are actually unsigned 8-bit integers. The reason for this is that ```float64``` values can show much more finegrained variation, which allow us to detect edges much more accurately.\n",
    "\n",
    "In order to work with the edges for the rest of our workflow, we need to convert back to unsiged integers, which we can do in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then see how these look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = np.hstack([sobelX, sobelY])\n",
    "jimshow_channel(blurred, \"Horizontal vs vertical Sobel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Sobel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to combine the gradient images in both the x and y direction, we can apply a bitwise OR. \n",
    "\n",
    "Remember, an OR operation is true when either pixel is greater than zero. \n",
    "\n",
    "Therefore, a given pixel will be ```True``` if either a horizontal or vertical edge is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelCombined = cv2.bitwise_or(sobelX, sobelY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow_channel(sobelCombined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laplacian operator returns a single gradient, no need to perform two passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#laplacian to compute gradient magnitude\n",
    "lap = cv2.Laplacian(grey, cv2.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jimshow_channel(lap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
