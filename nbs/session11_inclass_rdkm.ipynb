{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49582d16-8369-4de0-ae31-e9d7b1a39213",
   "metadata": {},
   "source": [
    "# OCR - From images to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01cbea",
   "metadata": {},
   "source": [
    "In this notebook, we're going to see how we can extract text from images using the ```pytesseract``` library. However, we're going to touch on a lot of different skills we've learned this semester - including drawing on ideas from Language Analytics, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed64493-bba7-491b-8b68-d87c65eaebf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:19:58.666303Z",
     "iopub.status.busy": "2022-05-02T08:19:58.665804Z",
     "iopub.status.idle": "2022-05-02T08:19:58.675693Z",
     "shell.execute_reply": "2022-05-02T08:19:58.674344Z",
     "shell.execute_reply.started": "2022-05-02T08:19:58.666249Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic python tools\n",
    "import re, os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# OCR tools\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# util functions\n",
    "from utils.imutils import jimshow as show\n",
    "from utils.imutils import jimshow_channel as show_channel\n",
    "\n",
    "# data processing tools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# readymade spellchecker\n",
    "from autocorrect import Speller\n",
    "\n",
    "def clean_string(string):\n",
    "    \"\"\"Removes punctuation to assist in OCR correction\"\"\"\n",
    "    processed = string.replace(\"\\n\",\" \")\\\n",
    "                     .replace(\"\\n\\n\",\" \")\\\n",
    "                     .replace(\"__\",\" \")\\\n",
    "                     .replace(\" - \",\" \")\\\n",
    "                     .replace('-\"\"' ,\" \")\\\n",
    "                     .replace(\"|\", \"\")\\\n",
    "                     .replace(\"!\", \"\")\\\n",
    "                     .replace(\"\\s\\s\",\" \")\\\n",
    "                     .lstrip()\n",
    "    return \" \".join(processed.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b580d31b-1048-42ff-8117-efae16b4734c",
   "metadata": {},
   "source": [
    "## OCR using ```Tesseract```\n",
    "\n",
    "Tesseract/pytesseract is quite a rich library with lots of different functionality and small tweaks and tricks that can improve your OCR. Check out the documentation for more info:\n",
    "\n",
    "**Pytesseract:** [Github](https://github.com/h/pytesseract) <br><br>\n",
    "**Tesseract:** [Github](https://github.com/tesseract-ocr/tesseract); [Documentation](https://tesseract-ocr.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd3e08-0480-4ee3-acfb-90fa95a6d70c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:15:15.673722Z",
     "iopub.status.busy": "2022-05-02T08:15:15.673218Z",
     "iopub.status.idle": "2022-05-02T08:15:15.680060Z",
     "shell.execute_reply": "2022-05-02T08:15:15.679055Z",
     "shell.execute_reply.started": "2022-05-02T08:15:15.673668Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(\"..\", \n",
    "                        \"..\",\n",
    "                        \"cds-viz-data\",\n",
    "                        \"data\", \n",
    "                        \"img\", \n",
    "                        \"jefferson.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72312f24",
   "metadata": {},
   "source": [
    "The simplest way of using ```pytesseract``` is simply to call the ```.image_to_string()```. As the name suggests, this produces a single string with all of the text content found in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09bc55-a216-40b9-aa60-5e6f9787c64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:15:16.264825Z",
     "iopub.status.busy": "2022-05-02T08:15:16.263609Z",
     "iopub.status.idle": "2022-05-02T08:15:18.378799Z",
     "shell.execute_reply": "2022-05-02T08:15:18.377146Z",
     "shell.execute_reply.started": "2022-05-02T08:15:16.264743Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(filepath)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f117bf",
   "metadata": {},
   "source": [
    "The library also has a method for returning the information as a dataframe which contains a detailed collection of information about its predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349b7da-5c32-4d32-b73a-ef264e8dad08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:15:40.014500Z",
     "iopub.status.busy": "2022-05-02T08:15:40.014007Z",
     "iopub.status.idle": "2022-05-02T08:15:42.005145Z",
     "shell.execute_reply": "2022-05-02T08:15:42.004540Z",
     "shell.execute_reply.started": "2022-05-02T08:15:40.014444Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pytesseract.image_to_data(filepath, \n",
    "                               output_type='data.frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62794e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60caa12a-b4c1-4c8b-a355-3cba7566e9d3",
   "metadata": {},
   "source": [
    "## Preprocess with Open-CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb400fb-9209-4933-8227-2ced3534ed2b",
   "metadata": {},
   "source": [
    "Note that Tesseract on Github give a bunch of tips for how best to preprocess images to improve performance. \n",
    "\n",
    "You should have the skills to actually do all of these things using OpenCV: https://github.com/tesseract-ocr/tessdoc/blob/main/ImproveQuality.md#rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e4cd5-244a-48ef-b326-2747cb5bf7f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:17:37.184050Z",
     "iopub.status.busy": "2022-05-02T08:17:37.183533Z",
     "iopub.status.idle": "2022-05-02T08:17:37.381681Z",
     "shell.execute_reply": "2022-05-02T08:17:37.380964Z",
     "shell.execute_reply.started": "2022-05-02T08:17:37.183994Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ffa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ec601-241f-4ebf-afeb-e000ce06171a",
   "metadata": {},
   "source": [
    "__Crop__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b6b82",
   "metadata": {},
   "source": [
    "The first thing we want to do is to crop this around the center of the image to keep only the main text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b2f8e-f43f-4aba-a45a-216382e8c49e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:18:12.701700Z",
     "iopub.status.busy": "2022-05-02T08:18:12.701170Z",
     "iopub.status.idle": "2022-05-02T08:18:12.709571Z",
     "shell.execute_reply": "2022-05-02T08:18:12.708373Z",
     "shell.execute_reply.started": "2022-05-02T08:18:12.701645Z"
    }
   },
   "outputs": [],
   "source": [
    "(cX, cY) = (image.shape[1]//2, image.shape[0]//2)\n",
    "cropped = image[cY-750:cY+1150, cX-750:cX+700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3d924-628a-44fb-a1f8-c735c1b782d7",
   "metadata": {},
   "source": [
    "__Greyscale__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde247e",
   "metadata": {},
   "source": [
    "Next, we greyscale the image to attempt to remove extra noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7d07b-497b-4001-b4e1-86b42451daa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:18:13.485604Z",
     "iopub.status.busy": "2022-05-02T08:18:13.485134Z",
     "iopub.status.idle": "2022-05-02T08:18:13.501766Z",
     "shell.execute_reply": "2022-05-02T08:18:13.500319Z",
     "shell.execute_reply.started": "2022-05-02T08:18:13.485550Z"
    }
   },
   "outputs": [],
   "source": [
    "grey = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ea391-b6f4-40c4-b7d6-0252c89c2e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:20:03.459148Z",
     "iopub.status.busy": "2022-05-02T08:20:03.458653Z",
     "iopub.status.idle": "2022-05-02T08:20:04.357845Z",
     "shell.execute_reply": "2022-05-02T08:20:04.357240Z",
     "shell.execute_reply.started": "2022-05-02T08:20:03.459091Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_channel(grey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e2951-8ac4-494e-b644-88c90123d26c",
   "metadata": {},
   "source": [
    "__OCR again__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab8173",
   "metadata": {},
   "source": [
    "Let's see how these simple steps improve performance of the OCR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fec800-321d-494c-a164-bb5beba433f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:20:30.150830Z",
     "iopub.status.busy": "2022-05-02T08:20:30.150308Z",
     "iopub.status.idle": "2022-05-02T08:20:31.987429Z",
     "shell.execute_reply": "2022-05-02T08:20:31.986620Z",
     "shell.execute_reply.started": "2022-05-02T08:20:30.150775Z"
    }
   },
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478cad9-3ac3-475e-9c13-c9cc6d9349dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:20:36.698236Z",
     "iopub.status.busy": "2022-05-02T08:20:36.697584Z",
     "iopub.status.idle": "2022-05-02T08:20:36.705029Z",
     "shell.execute_reply": "2022-05-02T08:20:36.703979Z",
     "shell.execute_reply.started": "2022-05-02T08:20:36.698177Z"
    }
   },
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20274cbe-87f8-4087-9fd1-ebb7d0ad8840",
   "metadata": {},
   "source": [
    "__Thresholding__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339132b0",
   "metadata": {},
   "source": [
    "Way back when we worked more with OpenCV, we learned that we could also *binarize* images using thresholding to make everything black or white (like when we created *masks*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83891b-8214-4e54-9a73-6243f1f73465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:20:53.550897Z",
     "iopub.status.busy": "2022-05-02T08:20:53.550370Z",
     "iopub.status.idle": "2022-05-02T08:20:53.563566Z",
     "shell.execute_reply": "2022-05-02T08:20:53.561336Z",
     "shell.execute_reply.started": "2022-05-02T08:20:53.550841Z"
    }
   },
   "outputs": [],
   "source": [
    "# threshold\n",
    "(T, thres) = cv2.threshold(grey, 110, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e676de-af70-483e-9188-b7984b538755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:21:00.687166Z",
     "iopub.status.busy": "2022-05-02T08:21:00.686655Z",
     "iopub.status.idle": "2022-05-02T08:21:01.222623Z",
     "shell.execute_reply": "2022-05-02T08:21:01.221271Z",
     "shell.execute_reply.started": "2022-05-02T08:21:00.687111Z"
    }
   },
   "outputs": [],
   "source": [
    "show_channel(thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ccba6-8a8f-4680-8869-98887b105a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:24:58.775628Z",
     "iopub.status.busy": "2022-05-02T08:24:58.775058Z",
     "iopub.status.idle": "2022-05-02T08:24:59.690604Z",
     "shell.execute_reply": "2022-05-02T08:24:59.688867Z",
     "shell.execute_reply.started": "2022-05-02T08:24:58.775561Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3d1d9-5369-4a9a-8bae-43bcae4f7aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:25:00.533583Z",
     "iopub.status.busy": "2022-05-02T08:25:00.533131Z",
     "iopub.status.idle": "2022-05-02T08:25:00.540113Z",
     "shell.execute_reply": "2022-05-02T08:25:00.539063Z",
     "shell.execute_reply.started": "2022-05-02T08:25:00.533530Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f805614-fa67-41ed-ba19-95614e259523",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quick and cheap spell checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b68dc3",
   "metadata": {},
   "source": [
    "One of the main issues we seem to see is single-character errors which give misspelled words. So, let's see how far we can get by doing some simple spell checking and correction with the ```autocorrect``` library:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c013d9-ceee-4ffc-bcbe-944876444990",
   "metadata": {},
   "source": [
    "__Initialize speller__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7b07a-4325-44d0-9582-454122b808e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:26:24.740086Z",
     "iopub.status.busy": "2022-05-02T08:26:24.739578Z",
     "iopub.status.idle": "2022-05-02T08:26:24.819909Z",
     "shell.execute_reply": "2022-05-02T08:26:24.818802Z",
     "shell.execute_reply.started": "2022-05-02T08:26:24.740030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spell = Speller(only_replacements=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = clean_string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb26f03-ddff-4359-902c-2f6e9d0c818e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T08:26:41.998158Z",
     "iopub.status.busy": "2022-05-02T08:26:41.997503Z",
     "iopub.status.idle": "2022-05-02T08:26:42.042238Z",
     "shell.execute_reply": "2022-05-02T08:26:42.041154Z",
     "shell.execute_reply.started": "2022-05-02T08:26:41.998100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spell(cleaned.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3490f64",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "__Spell checking with generative LLMs__\n",
    "- Head over to HuggingChat and check out some of the newest LLMs perform on this task. Test all of the available models and ask the following questions\n",
    "\n",
    "__Some test images__\n",
    "\n",
    "- I've attached some links to culturally significant images below. How well does the OCR pipeline work on these images? What do you need to do to get it to work? What does this suggest about the challenges or limitations of OCR?\n",
    "    - [Image 1](https://www.techsmith.com/blog/wp-content/uploads/2021/09/Make-a-meme-butterfly.png)\n",
    "    - [Image 2](https://datasciencedojo.com/wp-content/uploads/52.jpg)\n",
    "    - [Image 3](https://datasciencedojo.com/wp-content/uploads/36.png)\n",
    "    - [Image 4 (an actually serious example)](https://upload.wikimedia.org/wikipedia/commons/7/7e/King_James_Bible-Isaiah_26.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
